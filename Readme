A machine learning (ML)-based application that generates neuroscience-informed music to calm the mind leverages real-time biofeedback and advanced algorithms to create personalized, emotionally responsive soundscapes. These systems use physiological signals like EEG, galvanic skin response (GSR), and heart rate variability (HRV) to detect a user's emotional state and then dynamically adjust music parameters—such as volume, rhythm, harmony, and timbre—to promote relaxation, reduce stress, and guide the brain into desired mental states like calmness or focus.
 The technology is grounded in neuroscience, aiming to synchronize brainwave activity through principles like brainwave entrainment, with some systems using deep learning models such as Transformers to convert EEG data directly into expressive musical features
